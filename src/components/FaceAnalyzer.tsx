'use client'

import { useEffect, useRef, useState } from 'react'
import * as faceapi from '@vladmandic/face-api'
import dynamic from 'next/dynamic'

// å‹•çš„ã«EmotionDashboardã‚’ã‚¤ãƒ³ãƒãƒ¼ãƒˆï¼ˆSSRã‚’ç„¡åŠ¹åŒ–ï¼‰
const EmotionDashboard = dynamic(() => import('./EmotionDashboard'), { ssr: false })

type Emotion = 'neutral' | 'happy' | 'sad' | 'angry' | 'fearful' | 'disgusted' | 'surprised'

// ãƒ—ãƒ­ãƒ‘ãƒ†ã‚£ã®å‹å®šç¾©ã‚’è¿½åŠ 
interface FaceAnalyzerProps {
  onFaceDetected?: (
    face: { x: number; y: number; width: number; height: number } | null,
    emotion: Emotion
  ) => void;
}

const emotionEmojis: Record<Emotion, string> = {
  neutral: 'ğŸ˜',
  happy: 'ğŸ˜„',
  sad: 'ğŸ˜¢',
  angry: 'ğŸ˜ ',
  fearful: 'ğŸ˜¨',
  disgusted: 'ğŸ¤¢',
  surprised: 'ğŸ˜²'
}

// æ„Ÿæƒ…ã®æ—¥æœ¬èªè¡¨è¨˜
const emotionLabels: Record<Emotion, string> = {
  neutral: 'ç„¡è¡¨æƒ…',
  happy: 'å–œã³',
  sad: 'æ‚²ã—ã¿',
  angry: 'æ€’ã‚Š',
  fearful: 'æã‚Œ',
  disgusted: 'å«Œæ‚ª',
  surprised: 'é©šã'
}

// æ„Ÿæƒ…ã®èª¬æ˜
const emotionDescriptions: Record<Emotion, string> = {
  neutral: 'ç‰¹ã«å¼·ã„æ„Ÿæƒ…ã¯è¡¨ã‚Œã¦ã„ã¾ã›ã‚“ã€‚å¹³é™ãªçŠ¶æ…‹ã§ã™ã€‚',
  happy: 'å–œã³ã®æ„Ÿæƒ…ãŒè¡¨ã‚Œã¦ã„ã¾ã™ã€‚ãƒã‚¸ãƒ†ã‚£ãƒ–ãªåå¿œã‚’ç¤ºã—ã¦ã„ã¾ã™ã€‚',
  sad: 'æ‚²ã—ã¿ã®æ„Ÿæƒ…ãŒè¡¨ã‚Œã¦ã„ã¾ã™ã€‚å¿ƒé…äº‹ãŒã‚ã‚‹å¯èƒ½æ€§ãŒã‚ã‚Šã¾ã™ã€‚',
  angry: 'æ€’ã‚Šã®æ„Ÿæƒ…ãŒè¡¨ã‚Œã¦ã„ã¾ã™ã€‚ä¸æº€ã‚’æ„Ÿã˜ã¦ã„ã¾ã™ã€‚',
  fearful: 'æã‚Œã®æ„Ÿæƒ…ãŒè¡¨ã‚Œã¦ã„ã¾ã™ã€‚ä¸å®‰ã‚’æ„Ÿã˜ã¦ã„ã‚‹ã‚ˆã†ã§ã™ã€‚',
  disgusted: 'å«Œæ‚ªã®æ„Ÿæƒ…ãŒè¡¨ã‚Œã¦ã„ã¾ã™ã€‚ä½•ã‹ã«å¯¾ã—ã¦å¦å®šçš„ãªåå¿œã‚’ã—ã¦ã„ã¾ã™ã€‚',
  surprised: 'é©šãã®æ„Ÿæƒ…ãŒè¡¨ã‚Œã¦ã„ã¾ã™ã€‚äºˆæƒ³å¤–ã®æƒ…å ±ã«åå¿œã—ã¦ã„ã¾ã™ã€‚'
}

// ãƒ¢ãƒ‡ãƒ«ã®CDN URL
const MODEL_URL = 'https://cdn.jsdelivr.net/npm/@vladmandic/face-api/model';

export default function FaceAnalyzer({ onFaceDetected }: FaceAnalyzerProps) {
  const videoRef = useRef<HTMLVideoElement>(null)
  const canvasRef = useRef<HTMLCanvasElement>(null)
  const containerRef = useRef<HTMLDivElement>(null)
  
  const [isModelLoaded, setIsModelLoaded] = useState(false)
  const [currentEmotion, setCurrentEmotion] = useState<Emotion>('neutral')
  const [allEmotions, setAllEmotions] = useState<Record<Emotion, number> | null>(null)
  const [fps, setFps] = useState(0)
  const [dimensions, setDimensions] = useState({ width: 640, height: 480 })
  const [isStreamStarted, setIsStreamStarted] = useState(false)
  const [error, setError] = useState<string | null>(null)
  const [showControls, setShowControls] = useState(false)
  const [isDetecting, setIsDetecting] = useState(true)
  const [modelSize, setModelSize] = useState<'tiny' | 'normal'>('tiny')
  const [detectedFace, setDetectedFace] = useState<faceapi.FaceDetection | null>(null)
  const [isListening, setIsListening] = useState(false)
  const [audioVisualization, setAudioVisualization] = useState<number[]>(Array(20).fill(0))
  
  // éŸ³å£°ã®ã‚·ãƒŸãƒ¥ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³
  useEffect(() => {
    if (isListening) {
      const simulateAudio = () => {
        const newVisualization = audioVisualization.map(() => {
          // ãƒ©ãƒ³ãƒ€ãƒ ãªæ³¢å½¢ã‚’ç”Ÿæˆï¼ˆå€¤ãŒå¤§ãã„ã»ã©é«˜ã„æ³¢å½¢ã«ãªã‚‹ï¼‰
          return Math.random() * 0.8 + 0.2; // 0.2ï½1.0ã®ç¯„å›²ã§å¤‰å‹•
        });
        setAudioVisualization(newVisualization);
      };
      
      // 100msã”ã¨ã«æ³¢å½¢ã‚’æ›´æ–°
      const interval = setInterval(simulateAudio, 100);
      return () => clearInterval(interval);
    } else {
      // ãƒªã‚¹ãƒ‹ãƒ³ã‚°çŠ¶æ…‹ã§ãªã„å ´åˆã¯å¾ã€…ã«æ³¢å½¢ã‚’å°ã•ãã™ã‚‹
      const fadeOut = () => {
        setAudioVisualization(prev => 
          prev.map(value => Math.max(0, value * 0.9))
        );
      };
      
      const interval = setInterval(fadeOut, 100);
      return () => clearInterval(interval);
    }
  }, [isListening, audioVisualization]);
  
  // ãƒã‚¤ã‚¯ã®ON/OFFã‚’åˆ‡ã‚Šæ›¿ãˆã‚‹
  const toggleListening = () => {
    console.log("ãƒã‚¤ã‚¯ãƒœã‚¿ãƒ³ãŒã‚¯ãƒªãƒƒã‚¯ã•ã‚Œã¾ã—ãŸ");
    setIsListening(prev => !prev);
  };
  
  // ãƒ‘ãƒ¼ãƒ†ã‚£ã‚¯ãƒ«ã‚¨ãƒ•ã‚§ã‚¯ãƒˆã®ãŸã‚ã«é¡”ãƒ‡ãƒ¼ã‚¿ã‚’è¦ªã‚³ãƒ³ãƒãƒ¼ãƒãƒ³ãƒˆã«é€ä¿¡
  useEffect(() => {
    if (onFaceDetected && detectedFace) {
      onFaceDetected(
        {
          x: detectedFace.box.x,
          y: detectedFace.box.y,
          width: detectedFace.box.width,
          height: detectedFace.box.height
        },
        currentEmotion
      );
    } else if (onFaceDetected) {
      onFaceDetected(null, currentEmotion);
    }
  }, [detectedFace, currentEmotion, onFaceDetected]);
  
  // é¡”åˆ†æãƒ¢ãƒ‡ãƒ«ã‚’ãƒ­ãƒ¼ãƒ‰ã™ã‚‹
  const loadModels = async () => {
    try {
      console.log('ãƒ¢ãƒ‡ãƒ«ã®ãƒ­ãƒ¼ãƒ‰ã‚’é–‹å§‹ã—ã¦ã„ã¾ã™...');
      
      // å¿…è¦ãªãƒ¢ãƒ‡ãƒ«ã‚’ä¸¦è¡Œã—ã¦ãƒ­ãƒ¼ãƒ‰ï¼ˆCDNã‹ã‚‰ç›´æ¥ï¼‰
      await Promise.all([
        faceapi.nets.tinyFaceDetector.loadFromUri(MODEL_URL),
        faceapi.nets.faceLandmark68Net.loadFromUri(MODEL_URL),
        faceapi.nets.faceExpressionNet.loadFromUri(MODEL_URL)
      ]);
      
      setIsModelLoaded(true);
      console.log('é¡”åˆ†æãƒ¢ãƒ‡ãƒ«ã®ãƒ­ãƒ¼ãƒ‰ãŒå®Œäº†ã—ã¾ã—ãŸ');
    } catch (error) {
      console.error('ãƒ¢ãƒ‡ãƒ«ã®ãƒ­ãƒ¼ãƒ‰ä¸­ã«ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ:', error);
      setError(`ãƒ¢ãƒ‡ãƒ«ã®ãƒ­ãƒ¼ãƒ‰ä¸­ã«ã‚¨ãƒ©ãƒ¼: ${error instanceof Error ? error.message : String(error)}`);
    }
  }
  
  // ã‚«ãƒ¡ãƒ©ã‚¹ãƒˆãƒªãƒ¼ãƒ ã‚’é–‹å§‹
  const startVideo = async () => {
    if (!videoRef.current) {
      setError('ãƒ“ãƒ‡ã‚ªè¦ç´ ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“');
      return;
    }
    
    try {
      console.log('ã‚«ãƒ¡ãƒ©ã¸ã®ã‚¢ã‚¯ã‚»ã‚¹ã‚’ãƒªã‚¯ã‚¨ã‚¹ãƒˆä¸­...');
      
      // æ˜ç¤ºçš„ã«ã‚«ãƒ¡ãƒ©ã¸ã®ã‚¢ã‚¯ã‚»ã‚¹ã‚’è¦æ±‚
      const stream = await navigator.mediaDevices.getUserMedia({
        video: { 
          width: { ideal: dimensions.width },
          height: { ideal: dimensions.height },
          facingMode: 'user'
        },
        audio: false
      });
      
      console.log('ã‚«ãƒ¡ãƒ©ã‚¢ã‚¯ã‚»ã‚¹è¨±å¯ã•ã‚Œã¾ã—ãŸ');
      
      // ãƒ“ãƒ‡ã‚ªè¦ç´ ã«ã‚¹ãƒˆãƒªãƒ¼ãƒ ã‚’è¨­å®š
      videoRef.current.srcObject = stream;
      
      // ãƒ“ãƒ‡ã‚ªãŒèª­ã¿è¾¼ã¾ã‚ŒãŸæ™‚ã®å‡¦ç†
      videoRef.current.onloadedmetadata = () => {
        console.log('ãƒ“ãƒ‡ã‚ªãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿ãŒãƒ­ãƒ¼ãƒ‰ã•ã‚Œã¾ã—ãŸ');
        if (videoRef.current) {
          videoRef.current.play().then(() => {
            console.log('ãƒ“ãƒ‡ã‚ªå†ç”Ÿé–‹å§‹');
            setIsStreamStarted(true);
          }).catch(err => {
            console.error('ãƒ“ãƒ‡ã‚ªå†ç”Ÿã‚¨ãƒ©ãƒ¼:', err);
            setError(`ãƒ“ãƒ‡ã‚ªå†ç”Ÿã‚¨ãƒ©ãƒ¼: ${err.message}`);
          });
        }
      };
    } catch (error) {
      console.error('ã‚«ãƒ¡ãƒ©ã¸ã®ã‚¢ã‚¯ã‚»ã‚¹ä¸­ã«ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ:', error);
      if (error instanceof DOMException && error.name === 'NotAllowedError') {
        setError('ã‚«ãƒ¡ãƒ©ã¸ã®ã‚¢ã‚¯ã‚»ã‚¹ãŒæ‹’å¦ã•ã‚Œã¾ã—ãŸã€‚ãƒ–ãƒ©ã‚¦ã‚¶ã®è¨­å®šã§ã‚«ãƒ¡ãƒ©ã¸ã®ã‚¢ã‚¯ã‚»ã‚¹ã‚’è¨±å¯ã—ã¦ãã ã•ã„ã€‚');
      } else if (error instanceof DOMException && error.name === 'NotFoundError') {
        setError('ã‚«ãƒ¡ãƒ©ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã€‚ã‚«ãƒ¡ãƒ©ãŒæ¥ç¶šã•ã‚Œã¦ã„ã‚‹ã“ã¨ã‚’ç¢ºèªã—ã¦ãã ã•ã„ã€‚');
      } else {
        setError(`ã‚«ãƒ¡ãƒ©ã‚¨ãƒ©ãƒ¼: ${error instanceof Error ? error.message : String(error)}`);
      }
    }
  }
  
  // é¡”åˆ†æã‚’å®Ÿè¡Œ
  const detectFaces = async () => {
    if (!isModelLoaded || !videoRef.current || !canvasRef.current || !isDetecting) return;
    
    // ã‚­ãƒ£ãƒ³ãƒã‚¹ã®ã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆã‚’å–å¾—
    const canvas = canvasRef.current;
    const context = canvas.getContext('2d');
    if (!context) return;
    
    // ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹è¨ˆæ¸¬ã‚’é–‹å§‹
    const startTime = performance.now();
    
    try {
      // é¡”æ¤œå‡ºã‚’å®Ÿè¡Œï¼ˆãƒ¢ãƒ‡ãƒ«ã‚µã‚¤ã‚ºã«å¿œã˜ã¦è¨­å®šã‚’å¤‰æ›´ï¼‰
      const faceDetectorOptions = modelSize === 'tiny' 
        ? new faceapi.TinyFaceDetectorOptions({ inputSize: 320, scoreThreshold: 0.5 })
        : new faceapi.SsdMobilenetv1Options({ minConfidence: 0.5 });
        
      // é¡”æ¤œå‡ºã‚’å®Ÿè¡Œ
      const detections = await faceapi.detectAllFaces(
        videoRef.current,
        faceDetectorOptions
      )
        .withFaceLandmarks()
        .withFaceExpressions();
      
      // æ¤œå‡ºçµæœã‚’ã‚­ãƒ£ãƒ³ãƒã‚¹ã®ã‚µã‚¤ã‚ºã«åˆã‚ã›ã‚‹
      const resizedDetections = faceapi.resizeResults(detections, {
        width: canvas.width,
        height: canvas.height
      });
      
      // ã‚­ãƒ£ãƒ³ãƒã‚¹ã‚’ã‚¯ãƒªã‚¢
      context.clearRect(0, 0, canvas.width, canvas.height);
      
      // è¿‘æœªæ¥çš„ãªã‚¹ã‚­ãƒ£ãƒ³åŠ¹æœ
      context.strokeStyle = 'rgba(0, 255, 255, 0.2)';
      context.lineWidth = 1;
      
      // ã‚¹ã‚­ãƒ£ãƒ³ãƒ©ã‚¤ãƒ³ã®æç”»
      const scanLineY = (Date.now() % 2000) / 2000 * canvas.height;
      context.beginPath();
      context.moveTo(0, scanLineY);
      context.lineTo(canvas.width, scanLineY);
      context.stroke();
      
      // ã‚°ãƒªãƒƒãƒ‰ãƒ‘ã‚¿ãƒ¼ãƒ³ã®æç”»
      const gridSize = 40;
      context.beginPath();
      for (let x = 0; x < canvas.width; x += gridSize) {
        context.moveTo(x, 0);
        context.lineTo(x, canvas.height);
      }
      for (let y = 0; y < canvas.height; y += gridSize) {
        context.moveTo(0, y);
        context.lineTo(canvas.width, y);
      }
      context.stroke();
      
      // æ¤œå‡ºçµæœã‚’æç”»
      if (resizedDetections.length > 0) {
        const detection = resizedDetections[0];
        setDetectedFace(detection.detection);
        
        // ã‚«ã‚¹ã‚¿ãƒ æç”»ã‚¹ã‚¿ã‚¤ãƒ«
        const drawOptions = {
          lineWidth: 2,
          drawLines: true,
          color: 'rgba(0, 255, 255, 0.8)'
        };
        
        // é¡”ã®è¼ªéƒ­ã¨ç‰¹å¾´ç‚¹ã‚’æç”»
        faceapi.draw.drawFaceLandmarks(canvas, resizedDetections);
        
        // é¡”æ¤œå‡ºãƒœãƒƒã‚¯ã‚¹ã‚’ã‚«ã‚¹ã‚¿ãƒ æç”»
        const box = detection.detection.box;
        
        // é¡”ã®å‘¨ã‚Šã«è¿‘æœªæ¥çš„ãªãƒœãƒƒã‚¯ã‚¹ã‚’æç”»
        context.strokeStyle = 'rgba(0, 255, 255, 0.8)';
        context.lineWidth = 2;
        
        // ãƒœãƒƒã‚¯ã‚¹ã®è§’ã®ã¿ã‚’æç”»ã—ã¦æœªæ¥çš„ãªé›°å›²æ°—ã«
        const cornerSize = 20;
        
        // å·¦ä¸Š
        context.beginPath();
        context.moveTo(box.x, box.y + cornerSize);
        context.lineTo(box.x, box.y);
        context.lineTo(box.x + cornerSize, box.y);
        context.stroke();
        
        // å³ä¸Š
        context.beginPath();
        context.moveTo(box.x + box.width - cornerSize, box.y);
        context.lineTo(box.x + box.width, box.y);
        context.lineTo(box.x + box.width, box.y + cornerSize);
        context.stroke();
        
        // å·¦ä¸‹
        context.beginPath();
        context.moveTo(box.x, box.y + box.height - cornerSize);
        context.lineTo(box.x, box.y + box.height);
        context.lineTo(box.x + cornerSize, box.y + box.height);
        context.stroke();
        
        // å³ä¸‹
        context.beginPath();
        context.moveTo(box.x + box.width - cornerSize, box.y + box.height);
        context.lineTo(box.x + box.width, box.y + box.height);
        context.lineTo(box.x + box.width, box.y + box.height - cornerSize);
        context.stroke();
        
        // æœ€ã‚‚ç¢ºç‡ãŒé«˜ã„æ„Ÿæƒ…ã‚’å–å¾—
        const expressions = detection.expressions;
        let maxExpression: Emotion = 'neutral';
        let maxProbability = 0;
        
        // ã™ã¹ã¦ã®æ„Ÿæƒ…ãƒ‡ãƒ¼ã‚¿ã‚’ã‚¹ãƒ†ãƒ¼ãƒˆã«ä¿å­˜
        const emotionsData: Record<Emotion, number> = {
          neutral: 0,
          happy: 0,
          sad: 0,
          angry: 0,
          fearful: 0,
          disgusted: 0,
          surprised: 0
        };
        
        Object.entries(expressions).forEach(([expression, probability]) => {
          if (expression in emotionEmojis) {
            const emotionKey = expression as Emotion;
            emotionsData[emotionKey] = probability;
            
            if (probability > maxProbability) {
              maxProbability = probability;
              maxExpression = emotionKey;
            }
          }
        });
        
        setCurrentEmotion(maxExpression);
        setAllEmotions(emotionsData);
        
        // é¡”ã®å·¦å´ã«æ„Ÿæƒ…ãƒ‡ãƒ¼ã‚¿ã‚’è¡¨ç¤º
        const dataStartX = Math.max(10, box.x - 260); // å·¦å´ã«é…ç½®ã€ç”»é¢å¤–ã«å‡ºãªã„ã‚ˆã†èª¿æ•´
        const dataStartY = box.y;
        
        // ãƒ‡ãƒ¼ã‚¿ãƒœãƒƒã‚¯ã‚¹ã®èƒŒæ™¯
        context.fillStyle = 'rgba(0, 0, 0, 0.6)';
        context.fillRect(dataStartX, dataStartY, 240, 180);
        context.strokeStyle = 'rgba(0, 255, 255, 0.8)';
        context.strokeRect(dataStartX, dataStartY, 240, 180);
        
        // ãƒ˜ãƒƒãƒ€ãƒ¼ãƒ©ã‚¤ãƒ³
        context.beginPath();
        context.moveTo(dataStartX, dataStartY + 30);
        context.lineTo(dataStartX + 240, dataStartY + 30);
        context.stroke();
        
        // ã‚¿ã‚¤ãƒˆãƒ«
        context.fillStyle = 'rgba(0, 255, 255, 0.8)';
        context.font = '16px monospace';
        context.fillText('FACIAL ANALYSIS', dataStartX + 10, dataStartY + 20);
        
        // ç¾åœ¨ã®æ„Ÿæƒ…
        context.font = '14px monospace';
        context.fillText('æ¤œå‡ºæ„Ÿæƒ…:', dataStartX + 10, dataStartY + 50);
        context.fillStyle = 'white';
        context.font = 'bold 18px monospace';
        context.fillText(`${emotionLabels[maxExpression]} (${(maxProbability * 100).toFixed(1)}%)`, dataStartX + 10, dataStartY + 75);
        
        // æ¨ªç·š
        context.strokeStyle = 'rgba(0, 255, 255, 0.4)';
        context.beginPath();
        context.moveTo(dataStartX, dataStartY + 90);
        context.lineTo(dataStartX + 240, dataStartY + 90);
        context.stroke();
        
        // ä¸Šä½3æ„Ÿæƒ…ã®ãƒãƒ¼è¡¨ç¤º
        context.fillStyle = 'rgba(0, 255, 255, 0.8)';
        context.font = '12px monospace';
        context.fillText('æ„Ÿæƒ…ç¢ºç‡åˆ†å¸ƒ:', dataStartX + 10, dataStartY + 110);
        
        // æ„Ÿæƒ…ç¢ºç‡ã®é™é †ã§ã‚½ãƒ¼ãƒˆ
        const sortedEmotions = Object.entries(emotionsData)
          .sort(([, a], [, b]) => b - a)
          .slice(0, 3);
        
        sortedEmotions.forEach(([emotion, probability], index) => {
          const barY = dataStartY + 125 + (index * 18);
          
          // æ„Ÿæƒ…ãƒ©ãƒ™ãƒ«
          context.fillStyle = 'white';
          context.font = '12px monospace';
          context.fillText(emotionLabels[emotion as Emotion], dataStartX + 10, barY);
          
          // ç¢ºç‡ãƒãƒ¼
          const barWidth = probability * 120;
          context.fillStyle = 'rgba(0, 255, 255, 0.3)';
          context.fillRect(dataStartX + 90, barY - 10, 120, 12);
          context.fillStyle = 'rgba(0, 255, 255, 0.8)';
          context.fillRect(dataStartX + 90, barY - 10, barWidth, 12);
          
          // ç¢ºç‡å€¤
          context.fillStyle = 'white';
          context.font = '10px monospace';
          context.fillText(`${(probability * 100).toFixed(1)}%`, dataStartX + 215, barY);
        });
      } else {
        // é¡”ãŒæ¤œå‡ºã•ã‚Œãªã„å ´åˆã€ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆçŠ¶æ…‹ã«ãƒªã‚»ãƒƒãƒˆ
        setCurrentEmotion('neutral');
        setDetectedFace(null);
      }
    } catch (err) {
      console.error('é¡”æ¤œå‡ºä¸­ã«ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ:', err);
    }
    
    // FPSã‚’è¨ˆç®—
    const endTime = performance.now();
    const elapsed = endTime - startTime;
    setFps(Math.round(1000 / elapsed));
    
    // æ¬¡ã®ãƒ•ãƒ¬ãƒ¼ãƒ ã§å†å®Ÿè¡Œ
    requestAnimationFrame(detectFaces);
  }
  
  // ãƒ¢ãƒ‡ãƒ«ã‚µã‚¤ã‚ºã‚’åˆ‡ã‚Šæ›¿ãˆã‚‹
  const toggleModelSize = () => {
    setModelSize(prev => prev === 'tiny' ? 'normal' : 'tiny');
  }
  
  // é¡”æ¤œå‡ºã®ä¸€æ™‚åœæ­¢/å†é–‹ã‚’åˆ‡ã‚Šæ›¿ãˆã‚‹
  const toggleDetection = () => {
    setIsDetecting(prev => !prev);
    if (!isDetecting && isStreamStarted) {
      // æ¤œå‡ºã‚’å†é–‹ã™ã‚‹å ´åˆ
      requestAnimationFrame(detectFaces);
    }
  }
  
  // ã‚³ãƒ³ãƒãƒ¼ãƒãƒ³ãƒˆã®åˆæœŸåŒ–
  useEffect(() => {
    console.log('ã‚³ãƒ³ãƒãƒ¼ãƒãƒ³ãƒˆãŒåˆæœŸåŒ–ã•ã‚Œã¾ã—ãŸ');
    loadModels();
    
    // ã‚¯ãƒªãƒ¼ãƒ³ã‚¢ãƒƒãƒ—é–¢æ•°
    return () => {
      // ã‚«ãƒ¡ãƒ©ã‚¹ãƒˆãƒªãƒ¼ãƒ ã‚’åœæ­¢
      if (videoRef.current && videoRef.current.srcObject) {
        const stream = videoRef.current.srcObject as MediaStream;
        stream.getTracks().forEach(track => track.stop());
      }
    };
  }, []);
  
  // ãƒ¢ãƒ‡ãƒ«ãŒãƒ­ãƒ¼ãƒ‰ã•ã‚ŒãŸã‚‰ã‚«ãƒ¡ãƒ©ã‚’é–‹å§‹
  useEffect(() => {
    if (isModelLoaded) {
      console.log('ãƒ¢ãƒ‡ãƒ«ãŒãƒ­ãƒ¼ãƒ‰ã•ã‚ŒãŸã®ã§ã‚«ãƒ¡ãƒ©ã‚’é–‹å§‹ã—ã¾ã™');
      startVideo();
    }
  }, [isModelLoaded]);
  
  // ã‚«ãƒ¡ãƒ©ã‚¹ãƒˆãƒªãƒ¼ãƒ ãŒé–‹å§‹ã•ã‚ŒãŸã‚‰é¡”æ¤œå‡ºã‚’é–‹å§‹
  useEffect(() => {
    if (isStreamStarted && videoRef.current) {
      console.log('ã‚«ãƒ¡ãƒ©ã‚¹ãƒˆãƒªãƒ¼ãƒ ãŒé–‹å§‹ã•ã‚ŒãŸã®ã§é¡”æ¤œå‡ºã‚’é–‹å§‹ã—ã¾ã™');
      
      // ã‚­ãƒ£ãƒ³ãƒã‚¹ã®ã‚µã‚¤ã‚ºã‚’ãƒ“ãƒ‡ã‚ªã«åˆã‚ã›ã‚‹
      if (canvasRef.current && videoRef.current) {
        canvasRef.current.width = videoRef.current.clientWidth;
        canvasRef.current.height = videoRef.current.clientHeight;
      }
      
      setIsDetecting(true);
      detectFaces();
    }
  }, [isStreamStarted]);
  
  // ã‚³ãƒ³ãƒ†ãƒŠã®ã‚µã‚¤ã‚ºã‚’èª¿æ•´
  useEffect(() => {
    const updateDimensions = () => {
      if (containerRef.current) {
        // ã‚µã‚¤ãƒ‰ãƒãƒ¼ã®å¹…ã‚’ç”»é¢å¹…ã®35%ã¨ã—ã¦è¨ˆç®—
        const screenWidth = window.innerWidth;
        const screenHeight = window.innerHeight;
        const sidebarWidth = Math.floor(screenWidth * 0.35); // 35%ã®ã‚µã‚¤ãƒ‰ãƒãƒ¼å¹…
        const padding = 48; // å·¦å³ã®ãƒ‘ãƒ‡ã‚£ãƒ³ã‚°åˆè¨ˆ (px)
        const rightMargin = 40; // å³å´ã®ä½™ç™½ (px)
        const headerHeight = 80; // ãƒ˜ãƒƒãƒ€ãƒ¼ã®é«˜ã• (px)
        const bottomMargin = 120; // ä¸‹éƒ¨ã®ä½™ç™½ã¨ä»–ã®è¦ç´ ã®ãŸã‚ã®ä½™ç™½ (px)
        
        // ä½¿ç”¨å¯èƒ½ãªæœ€å¤§å¹…ã‚’è¨ˆç®—ï¼ˆãƒ¡ã‚¤ãƒ³ã‚³ãƒ³ãƒ†ãƒ³ãƒ„ã‚¨ãƒªã‚¢ = 65%ã‹ã‚‰ä½™ç™½ã‚’é™¤ãï¼‰
        const availableWidth = screenWidth - sidebarWidth - padding - rightMargin;
        // ä½¿ç”¨å¯èƒ½ãªæœ€å¤§é«˜ã•ã‚’è¨ˆç®—
        const availableHeight = screenHeight - headerHeight - bottomMargin;
        
        // ç”»é¢ã‚µã‚¤ã‚ºã«å¿œã˜ãŸé©åˆ‡ãªå¹…ã‚’è¨­å®š
        let width;
        if (screenWidth <= 768) {
          // ãƒ¢ãƒã‚¤ãƒ«: ã‚ˆã‚Šå°ã•ãªã‚µã‚¤ã‚º
          width = Math.max(320, Math.min(500, availableWidth));
        } else if (screenWidth <= 1024) {
          // ã‚¿ãƒ–ãƒ¬ãƒƒãƒˆ: ä¸­ç¨‹åº¦ã®ã‚µã‚¤ã‚º
          width = Math.max(480, Math.min(700, availableWidth));
        } else {
          // ãƒ‡ã‚¹ã‚¯ãƒˆãƒƒãƒ—: ã‚ˆã‚Šå¤§ããªã‚µã‚¤ã‚º
          width = Math.max(640, Math.min(900, availableWidth));
        }
        
        // 16:9ã®ã‚¢ã‚¹ãƒšã‚¯ãƒˆæ¯”ã‚’ä½¿ç”¨ï¼ˆã‚ˆã‚Šæ˜ åƒã«é©ã—ãŸãƒ¯ã‚¤ãƒ‰ãªã‚¢ã‚¹ãƒšã‚¯ãƒˆæ¯”ï¼‰
        let height = width * 9 / 16;
        
        // é«˜ã•ãŒåˆ©ç”¨å¯èƒ½ãªé«˜ã•ã‚’è¶…ãˆã‚‹å ´åˆã¯ã€é«˜ã•ã‚’åŸºæº–ã«å¹…ã‚’å†è¨ˆç®—
        if (height > availableHeight) {
          height = availableHeight;
          width = height * 16 / 9;
          
          // å†è¨ˆç®—ã•ã‚ŒãŸå¹…ãŒåˆ©ç”¨å¯èƒ½ãªå¹…ã‚’è¶…ãˆã‚‹å ´åˆã¯ã€ã•ã‚‰ã«èª¿æ•´
          if (width > availableWidth) {
            width = availableWidth;
            height = width * 9 / 16;
          }
        }
        
        // æœ€å°ã‚µã‚¤ã‚ºã®ä¿è¨¼
        width = Math.max(320, width);
        height = Math.max(180, height);
        
        setDimensions({ width: Math.floor(width), height: Math.floor(height) });
        
        // ã‚­ãƒ£ãƒ³ãƒã‚¹ã®ã‚µã‚¤ã‚ºã‚‚æ›´æ–°
        if (canvasRef.current) {
          canvasRef.current.width = Math.floor(width);
          canvasRef.current.height = Math.floor(height);
        }
      }
    };
    
    window.addEventListener('resize', updateDimensions);
    updateDimensions();
    
    return () => window.removeEventListener('resize', updateDimensions);
  }, []);
  
  // æ‰‹å‹•ã§ã‚«ãƒ¡ãƒ©ã‚¢ã‚¯ã‚»ã‚¹ã‚’è¦æ±‚ã™ã‚‹ãƒãƒ³ãƒ‰ãƒ©ãƒ¼
  const handleRequestCamera = () => {
    startVideo();
  };
  
  // ã‚«ãƒ¡ãƒ©ã‚³ãƒ³ãƒˆãƒ­ãƒ¼ãƒ«ã®è¡¨ç¤º/éè¡¨ç¤ºã‚’åˆ‡ã‚Šæ›¿ãˆã‚‹
  const toggleControls = () => {
    setShowControls(prev => !prev);
  };
  
  // èƒŒæ™¯è‰²ã®ã‚¯ãƒ©ã‚¹å
  const bgColorClass = `bg-${currentEmotion}`;
  
  return (
    <div className="flex flex-col items-center gap-4 w-full">
      
      <div className="relative w-full">
        <div 
          ref={containerRef}
          className="canvas-container bg-black/80 rounded-2xl shadow-lg overflow-hidden transition-colors duration-300 border border-cyan-500/40 mx-auto"
          style={{ width: dimensions.width, height: dimensions.height }}
        >
          <video
            ref={videoRef}
            className="webcam"
            width={dimensions.width}
            height={dimensions.height}
            autoPlay
            muted
            playsInline
          />
          <canvas
            ref={canvasRef}
            width={dimensions.width}
            height={dimensions.height}
          />
          
          {/* å·¦ä¸‹ã®ã‚¹ãƒ†ãƒ¼ã‚¿ã‚¹è¡¨ç¤º */}
          <div className="absolute bottom-3 left-3 bg-black/60 backdrop-blur-md text-cyan-400 rounded-lg p-2 z-10 border border-cyan-500/30 flex items-center space-x-2 text-xs">
            <div className="flex items-center">
              <div className={`w-2 h-2 rounded-full ${isDetecting ? 'bg-green-500 animate-pulse' : 'bg-red-500'} mr-1`}></div>
              <span>{isDetecting ? 'ACTIVE' : 'PAUSED'}</span>
            </div>
            <span>|</span>
            <span>FPS: {fps}</span>
            <span>|</span>
            <span>MODEL: {modelSize === 'tiny' ? 'FAST' : 'PRECISE'}</span>
          </div>
          
          {/* éŸ³å£°è§£æè¡¨ç¤ºï¼ˆä¸€ç•ªä¸‹ã«é…ç½®ï¼‰ */}
          <div className="absolute bottom-0 left-0 right-0 h-16 bg-gradient-to-t from-black/80 to-transparent flex items-end justify-center z-20">
            <div className="relative w-3/4 h-12 flex items-end justify-center pb-4">
              
              {/* éŸ³å£°æ³¢å½¢è¡¨ç¤º */}
              <div className="absolute w-full bottom-14 h-8 flex items-center justify-center gap-1">
                {audioVisualization.map((value, index) => (
                  <div 
                    key={index}
                    className="w-1 bg-gradient-to-t from-cyan-400 to-blue-500 rounded-t-sm"
                    style={{ 
                      height: `${value * 100}%`,
                      opacity: isListening ? 1 : 0.5,
                      transition: 'height 0.1s ease-in-out'
                    }}
                  ></div>
                ))}
              </div>
              
              {/* ãƒã‚¤ã‚¯ãƒœã‚¿ãƒ³ */}
              <button 
                onClick={toggleListening}
                className={`absolute bottom-4 left-1/2 transform -translate-x-1/2 w-20 h-20 rounded-full flex items-center justify-center z-30 transition-all duration-300 ${isListening ? 'bg-gradient-to-r from-cyan-500 to-blue-600 shadow-lg shadow-cyan-500/50' : 'bg-black/60 border border-cyan-500/30'}`}
              >
                <svg 
                  xmlns="http://www.w3.org/2000/svg" 
                  className="h-10 w-10" 
                  fill="none" 
                  viewBox="0 0 24 24" 
                  stroke="currentColor"
                  strokeWidth={2}
                  style={{ color: isListening ? 'white' : '#22d3ee' }}
                >
                  <path 
                    strokeLinecap="round" 
                    strokeLinejoin="round" 
                    d="M19 11a7 7 0 01-7 7m0 0a7 7 0 01-7-7m7 7v4m0 0H8m4 0h4m-4-8a3 3 0 01-3-3V5a3 3 0 116 0v6a3 3 0 01-3 3z" 
                  />
                </svg>
              </button>
              
              {/* ãƒªã‚¹ãƒ‹ãƒ³ã‚°çŠ¶æ…‹ãƒ†ã‚­ã‚¹ãƒˆ */}
              {isListening && (
                <div className="absolute bottom-36 left-1/2 transform -translate-x-1/2 bg-black/60 backdrop-blur-md text-cyan-400 rounded-lg px-2 py-1 text-xs border border-cyan-500/30">
                  VOICE ANALYSIS ACTIVE
                </div>
              )}
            </div>
          </div>
        </div>
        
        {/* Cristalãƒœã‚¿ãƒ³ - ãƒ“ãƒ‡ã‚ªæ ã®å³ç«¯ä¸‹éƒ¨ã«é…ç½® */}
        <div className="absolute bottom-3 right-0 z-50">
          {/* å…‰ã‚‹ãƒªãƒ³ã‚°ã‚¢ãƒ‹ãƒ¡ãƒ¼ã‚·ãƒ§ãƒ³ */}
          <div className="absolute inset-0 rounded-full bg-cyan-400/10 animate-pulse" style={{ width: '13rem', height: '13rem', margin: '-0.5rem' }}></div>
          <div className="absolute inset-0 rounded-full bg-cyan-500/15 animate-pulse" style={{ width: '12.5rem', height: '12.5rem', margin: '-0.25rem', animationDelay: '0.5s' }}></div>
          <div className="absolute inset-0 rounded-full bg-cyan-500/20 animate-pulse" style={{ width: '12rem', height: '12rem', margin: '-0.1rem', animationDelay: '1s' }}></div>
          
          <button 
            onClick={() => {
              // page.tsxã®handleCristalClické–¢æ•°ã‚’å‘¼ã³å‡ºã™ãŸã‚ã€ã‚«ã‚¹ã‚¿ãƒ ã‚¤ãƒ™ãƒ³ãƒˆã‚’ç™ºç«
              const event = new CustomEvent('cristalClick');
              window.dispatchEvent(event);
            }}
            className="w-48 h-48 rounded-full overflow-hidden transition-all duration-300 transform hover:scale-105 focus:outline-none shadow-lg shadow-cyan-500/30 hover:shadow-cyan-500/50 relative z-10"
          >
            <img src="/CRISTAL.png" alt="CRISTAL" className="w-full h-full object-cover pointer-events-none" />
          </button>
        </div>

        {/* ã‚³ãƒ³ãƒˆãƒ­ãƒ¼ãƒ«ãƒœã‚¿ãƒ³ */}
        <button 
          onClick={toggleControls}
          className="absolute top-3 right-3 bg-black/60 backdrop-blur-md text-cyan-400 rounded-full p-2 hover:bg-black/80 transition-all z-10 border border-cyan-500/30"
        >
          <svg xmlns="http://www.w3.org/2000/svg" className="h-5 w-5" viewBox="0 0 20 20" fill="currentColor">
            <path fillRule="evenodd" d="M11.49 3.17c-.38-1.56-2.6-1.56-2.98 0a1.532 1.532 0 01-2.286.948c-1.372-.836-2.942.734-2.106 2.106.54.886.061 2.042-.947 2.287-1.561.379-1.561 2.6 0 2.978a1.532 1.532 0 01.947 2.287c-.836 1.372.734 2.942 2.106 2.106a1.532 1.532 0 012.287.947c.379 1.561 2.6 1.561 2.978 0a1.533 1.533 0 012.287-.947c1.372.836 2.942-.734 2.106-2.106a1.533 1.533 0 01.947-2.287c1.561-.379 1.561-2.6 0-2.978a1.532 1.532 0 01-.947-2.287c.836-1.372-.734-2.942-2.106-2.106a1.532 1.532 0 01-2.287-.947zM10 13a3 3 0 100-6 3 3 0 000 6z" clipRule="evenodd" />
          </svg>
        </button>
        
        {showControls && (
          <div className="absolute top-12 right-3 bg-black/70 backdrop-blur-md text-cyan-400 rounded-lg p-3 z-10 border border-cyan-500/30">
            <h3 className="text-xs font-bold mb-2 text-center border-b border-cyan-500/30 pb-1">SYSTEM CONTROLS</h3>
            <div className="flex flex-col gap-2">
              <button 
                onClick={toggleDetection}
                className={`flex items-center gap-2 px-3 py-1 rounded-lg text-xs border ${isDetecting ? 'border-red-500/50 bg-red-500/20 hover:bg-red-500/30' : 'border-green-500/50 bg-green-500/20 hover:bg-green-500/30'} transition-colors`}
              >
                {isDetecting ? (
                  <>
                    <svg xmlns="http://www.w3.org/2000/svg" className="h-4 w-4" viewBox="0 0 20 20" fill="currentColor">
                      <path fillRule="evenodd" d="M18 10a8 8 0 11-16 0 8 8 0 0116 0zM7 8a1 1 0 012 0v4a1 1 0 11-2 0V8zm5-1a1 1 0 00-1 1v4a1 1 0 102 0V8a1 1 0 00-1-1z" clipRule="evenodd" />
                    </svg>
                    <span>PAUSE DETECTION</span>
                  </>
                ) : (
                  <>
                    <svg xmlns="http://www.w3.org/2000/svg" className="h-4 w-4" viewBox="0 0 20 20" fill="currentColor">
                      <path fillRule="evenodd" d="M10 18a8 8 0 100-16 8 8 0 000 16zM9.555 7.168A1 1 0 008 8v4a1 1 0 001.555.832l3-2a1 1 0 000-1.664l-3-2z" clipRule="evenodd" />
                    </svg>
                    <span>RESUME DETECTION</span>
                  </>
                )}
              </button>
              
              <button 
                onClick={toggleModelSize}
                className="flex items-center gap-2 px-3 py-1 rounded-lg text-xs border border-blue-500/50 bg-blue-500/20 hover:bg-blue-500/30 transition-colors"
              >
                <svg xmlns="http://www.w3.org/2000/svg" className="h-4 w-4" viewBox="0 0 20 20" fill="currentColor">
                  <path d="M5 4a1 1 0 00-2 0v7.268a2 2 0 000 3.464V16a1 1 0 102 0v-1.268a2 2 0 000-3.464V4zM11 4a1 1 0 10-2 0v1.268a2 2 0 000 3.464V16a1 1 0 102 0V8.732a2 2 0 000-3.464V4zM16 3a1 1 0 011 1v7.268a2 2 0 010 3.464V16a1 1 0 11-2 0v-1.268a2 2 0 010-3.464V4a1 1 0 011-1z" />
                </svg>
                <span>TOGGLE MODEL: {modelSize === 'tiny' ? 'FAST â†’ PRECISE' : 'PRECISE â†’ FAST'}</span>
              </button>
              
              {/* éŸ³å£°è§£æåˆ‡ã‚Šæ›¿ãˆãƒœã‚¿ãƒ³ */}
              <button 
                onClick={toggleListening}
                className={`flex items-center gap-2 px-3 py-1 rounded-lg text-xs border ${isListening ? 'border-cyan-500/50 bg-cyan-500/20 hover:bg-cyan-500/30' : 'border-gray-500/50 bg-gray-500/20 hover:bg-gray-500/30'} transition-colors`}
              >
                <svg xmlns="http://www.w3.org/2000/svg" className="h-4 w-4" viewBox="0 0 20 20" fill="currentColor">
                  <path fillRule="evenodd" d="M7 4a3 3 0 016 0v4a3 3 0 11-6 0V4zm4 10.93A7.001 7.001 0 0017 8a1 1 0 10-2 0A5 5 0 015 8a1 1 0 00-2 0 7.001 7.001 0 006 6.93V17H6a1 1 0 100 2h8a1 1 0 100-2h-3v-2.07z" clipRule="evenodd" />
                </svg>
                <span>{isListening ? 'DISABLE VOICE ANALYSIS' : 'ENABLE VOICE ANALYSIS'}</span>
              </button>
            </div>
          </div>
        )}
      </div>
      
      {/* æ„Ÿæƒ…çŠ¶æ…‹è¡¨ç¤º */}
      {detectedFace && (
        <div 
          className="bg-black/70 backdrop-blur-md rounded-xl p-4 border border-cyan-500/30"
          style={{ width: dimensions.width }}
        >
          <div className="flex justify-between items-center mb-3 border-b border-cyan-500/30 pb-2">
            <h3 className="text-cyan-400 text-sm font-bold">FACIAL ANALYSIS RESULTS</h3>
            <span className="text-cyan-400 text-xs">{new Date().toLocaleTimeString()}</span>
          </div>
          
          <div className="grid grid-cols-1 md:grid-cols-3 gap-4">
            {/* ç¾åœ¨ã®æ„Ÿæƒ… */}
            <div className="bg-black/50 rounded-lg p-3 border border-cyan-500/20">
              <h4 className="text-cyan-400 text-xs font-bold mb-2">PRIMARY EMOTION</h4>
              <div className="flex items-center space-x-3">
                <span className="text-3xl">{emotionEmojis[currentEmotion]}</span>
                <div>
                  <div className="text-white font-bold">{emotionLabels[currentEmotion]}</div>
                  <div className="text-gray-400 text-xs">{emotionDescriptions[currentEmotion]}</div>
                </div>
              </div>
            </div>
            
            {/* æ„Ÿæƒ…ã‚°ãƒ©ãƒ• */}
            <div className="bg-black/50 rounded-lg p-3 border border-cyan-500/20 col-span-2">
              <h4 className="text-cyan-400 text-xs font-bold mb-2">EMOTION DISTRIBUTION</h4>
              <div className="space-y-2">
                {allEmotions && Object.entries(allEmotions)
                  .sort(([, a], [, b]) => b - a)
                  .map(([emotion, value]) => (
                    <div key={emotion} className="flex items-center">
                      <span className="text-white text-xs w-16">{emotionLabels[emotion as Emotion]}</span>
                      <div className="flex-1 bg-gray-800 rounded-full h-2 ml-2">
                        <div 
                          className="h-2 rounded-full" 
                          style={{ 
                            width: `${value * 100}%`,
                            backgroundColor: emotion === currentEmotion ? 'rgb(6, 182, 212)' : 'rgba(6, 182, 212, 0.5)'
                          }}
                        ></div>
                      </div>
                      <span className="text-white text-xs w-12 text-right ml-2">{(value * 100).toFixed(1)}%</span>
                    </div>
                  ))
                }
              </div>
            </div>
          </div>
        </div>
      )}
      
      {/* ã‚¨ãƒ©ãƒ¼ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ */}
      {error && (
        <div 
          className="mt-2 text-sm text-red-400 bg-black/70 backdrop-blur-md p-4 rounded-xl border border-red-500/30"
          style={{ width: dimensions.width }}
        >
          <h3 className="text-red-400 text-xs font-bold mb-2">SYSTEM ERROR</h3>
          <p className="text-sm leading-relaxed">{error}</p>
          <button 
            onClick={handleRequestCamera}
            className="mt-3 px-4 py-2 bg-red-500/20 backdrop-blur-sm text-white rounded-lg hover:bg-red-500/30 transition-colors border border-red-500/30 text-xs font-medium"
          >
            RETRY CAMERA ACCESS
          </button>
        </div>
      )}
      
      {/* èª­ã¿è¾¼ã¿ä¸­è¡¨ç¤º */}
      {!isModelLoaded && !error && (
        <div 
          className="mt-2 text-sm text-cyan-400 bg-black/70 backdrop-blur-md p-4 rounded-xl border border-cyan-500/30"
          style={{ width: dimensions.width }}
        >
          <div className="flex items-center">
            <div className="animate-spin mr-2 h-4 w-4 border-2 border-cyan-400 border-t-transparent rounded-full"></div>
            <span>LOADING FACIAL RECOGNITION MODELS...</span>
          </div>
        </div>
      )}
      
      {isModelLoaded && !isStreamStarted && !error && (
        <div 
          className="mt-2 text-sm text-cyan-400 bg-black/70 backdrop-blur-md p-4 rounded-xl border border-cyan-500/30"
          style={{ width: dimensions.width }}
        >
          <div className="flex items-center">
            <div className="animate-pulse mr-2 h-4 w-4 bg-cyan-400 rounded-full"></div>
            <span>INITIALIZING CAMERA...</span>
          </div>
        </div>
      )}
    </div>
  );
} 